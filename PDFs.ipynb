{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-centre",
   "metadata": {},
   "source": [
    "[PyPDF2 Tutorial](https://roytuts.com/extract-text-from-pdf-file-using-python/) <br>\n",
    "[Tabula and Camelot Tutorial](https://www.geeksforgeeks.org/how-to-extract-pdf-tables-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-reward",
   "metadata": {},
   "source": [
    "Following code was pulled from [this](https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests) StackExchange post so an online pdf can be pulled without needing for a user to download a pdf and change the code. Only the url of the pdf they want to work with must be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promotional-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-space",
   "metadata": {},
   "source": [
    "## Using PyPDF2\n",
    "\n",
    "Documentation available [here](https://pypi.org/project/PyPDF2/) <br>\n",
    "We can pull a PDF from the web and scrape it as an exercise in downloading files from the web with Python, but the file is included if you'd like to change the code to only open the existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "julian-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text:  A Simple PDF File  This is a small demonstration .pdf file -  just for use in the Virtual Mechanics tutorials. More text. And more  text. And more text. And more text. And more text.  And more text. And more text. And more text. And more text. And more  text. And more text. Boring, zzzzz. And more text. And more text. And  more text. And more text. And more text. And more text. And more text.  And more text. And more text.  And more text. And more text. And more text. And more text. And more  text. And more text. And more text. Even more. Continued on page 2 ...\n",
      " Simple PDF File 2  ...continued from page 1. Yet more text. And more text. And more text.  And more text. And more text. And more text. And more text. And more  text. Oh, how boring typing this stuff. But not as boring as watching  paint dry. And more text. And more text. And more text. And more text.  Boring.  More, a little more text. The end, and just as well. \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 as pydf\n",
    "\n",
    "#Obtain file name\n",
    "file_name = download_file(\"http://www.africau.edu/images/default/sample.pdf\")\n",
    "#Open file\n",
    "pdf_file = open(file_name, 'rb')\n",
    "\n",
    "pdf_reader = pydf.PdfFileReader(pdf_file)\n",
    "page_count = pdf_reader.numPages\n",
    "text = []\n",
    "\n",
    "#Extract text from every page\n",
    "for page in range(page_count):\n",
    "    #Try except block in case of corrupted data\n",
    "    try:\n",
    "        pdf_page = pdf_reader.getPage(page)\n",
    "        text.append(pdf_page.extractText())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "full_text = \"\\n\".join(text)\n",
    "print(\"Full text: \" + full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-sharp",
   "metadata": {},
   "source": [
    "Note that since we're storing the text per page into a list collection you can easily search for text by page number accounting for the fact that list index starts at 0, where as PDF page counts will start at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hungarian-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String 'text' was found 40 times in the PDF\n"
     ]
    }
   ],
   "source": [
    "#This sample pdf contains the word \"text\" many times\n",
    "#Let's scrub the full string output to see exactly how many times.\n",
    "str_to_find = \"text\"\n",
    "print(f\"String '{str_to_find}' was found {full_text.count(str_to_find)} times in the PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-haiti",
   "metadata": {},
   "source": [
    "## Using Tabula and Camelot\n",
    "\n",
    "While we were able to learn to use PyPDF2 to extract plain text from PDF, some data may only be available in PDF format, in which case plain-text parsing will not suffice to retain formatting of the information. Tabula and Camelot provide means of solving this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "progressive-coupon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Span</th>\n",
       "      <th>Innings</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Highest</th>\n",
       "      <th>Average</th>\n",
       "      <th>Striking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Sachin Tendular</td>\n",
       "      <td>India</td>\n",
       "      <td>1989-2012</td>\n",
       "      <td>452.0</td>\n",
       "      <td>18426.0</td>\n",
       "      <td>200</td>\n",
       "      <td>44.83</td>\n",
       "      <td>86.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Kumar Sangakkara</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2000-2015</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14234.0</td>\n",
       "      <td>169</td>\n",
       "      <td>41.98</td>\n",
       "      <td>78.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Ricky Ponting</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1995-2012</td>\n",
       "      <td>365.0</td>\n",
       "      <td>13704.0</td>\n",
       "      <td>164</td>\n",
       "      <td>42.03</td>\n",
       "      <td>80.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Sanath Jayasuriya</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>1989-2011</td>\n",
       "      <td>433.0</td>\n",
       "      <td>13430.0</td>\n",
       "      <td>189</td>\n",
       "      <td>32.36</td>\n",
       "      <td>91.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Mahela Jayawardene</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>1998-2015</td>\n",
       "      <td>418.0</td>\n",
       "      <td>12650.0</td>\n",
       "      <td>144</td>\n",
       "      <td>33.37</td>\n",
       "      <td>78.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>India</td>\n",
       "      <td>2008-2020</td>\n",
       "      <td>236.0</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>183</td>\n",
       "      <td>59.85</td>\n",
       "      <td>93.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Inzamam-ul-Haq</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>1991-200</td>\n",
       "      <td>350.0</td>\n",
       "      <td>11739.0</td>\n",
       "      <td>137</td>\n",
       "      <td>39.52</td>\n",
       "      <td>74.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Jacques Kalis</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>1996-2014</td>\n",
       "      <td>314.0</td>\n",
       "      <td>11579.0</td>\n",
       "      <td>139</td>\n",
       "      <td>44.36</td>\n",
       "      <td>72.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Saurav Ganguly</td>\n",
       "      <td>India</td>\n",
       "      <td>1992-2007</td>\n",
       "      <td>300.0</td>\n",
       "      <td>11363.0</td>\n",
       "      <td>183</td>\n",
       "      <td>41.02</td>\n",
       "      <td>73.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Rahul Dravid</td>\n",
       "      <td>India</td>\n",
       "      <td>1996-2011</td>\n",
       "      <td>318.0</td>\n",
       "      <td>10889.0</td>\n",
       "      <td>153</td>\n",
       "      <td>39.16</td>\n",
       "      <td>71.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pos              Player          Team       Span  Innings     Runs  \\\n",
       "0    NaN                 NaN           NaN        NaN      NaN      NaN   \n",
       "1    1.0     Sachin Tendular         India  1989-2012    452.0  18426.0   \n",
       "2    2.0    Kumar Sangakkara     Sri Lanka  2000-2015    380.0  14234.0   \n",
       "3    3.0       Ricky Ponting     Australia  1995-2012    365.0  13704.0   \n",
       "4    4.0   Sanath Jayasuriya     Sri Lanka  1989-2011    433.0  13430.0   \n",
       "5    5.0  Mahela Jayawardene     Sri Lanka  1998-2015    418.0  12650.0   \n",
       "6    6.0         Virat Kohli         India  2008-2020    236.0  11867.0   \n",
       "7    7.0      Inzamam-ul-Haq      Pakistan   1991-200    350.0  11739.0   \n",
       "8    8.0       Jacques Kalis  South Africa  1996-2014    314.0  11579.0   \n",
       "9    9.0      Saurav Ganguly         India  1992-2007    300.0  11363.0   \n",
       "10  10.0        Rahul Dravid         India  1996-2011    318.0  10889.0   \n",
       "\n",
       "   Highest  Average Striking  \n",
       "0    Score      NaN     Rate  \n",
       "1      200    44.83    86.23  \n",
       "2      169    41.98    78.86  \n",
       "3      164    42.03    80.39  \n",
       "4      189    32.36     91.2  \n",
       "5      144    33.37    78.96  \n",
       "6      183    59.85    93.39  \n",
       "7      137    39.52    74.24  \n",
       "8      139    44.36    72.89  \n",
       "9      183    41.02     73.7  \n",
       "10     153    39.16    71.24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "from tabula import read_pdf\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "path = r'assets/Test.pdf'\n",
    "pdf_file = open(path, 'rb')\n",
    "#reads table from pdf file\n",
    "df = read_pdf(pdf_file, pages=\"all\",\n",
    "              output_format=\"dataframe\") #address of pdf file\n",
    "#Tabula read PDF returns a LIST of dataframes, access by index to use as data for DF\n",
    "df = pd.DataFrame(data=df[0])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-shanghai",
   "metadata": {},
   "source": [
    "Tabula tends to not play nice with messier PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "million-collect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, Total]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One of the PDFs provided in a data set for Matthew's replication\n",
    "path = r\"assets/t01_01.pdf\"\n",
    "df = read_pdf(path, pages=\"all\",\n",
    "              output_format=\"dataframe\")\n",
    "df = pd.DataFrame(data=df[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-liberia",
   "metadata": {},
   "source": [
    "Some PDFs are much harder for Tabula to read than others. One approach might be outputting with tabula to a CSV from a PDF and manually cleaning the data in Excel or some human-readable format. The rest of the cleaning can be handled once it's importable to Pandas, but that starting line of importing to a pandas DataFrame might need human effort.\n",
    "\n",
    "Camelot tends to be more flexible when it comes reading harder PDFs, but dependencies are quite annoying to handle with this library.\n",
    "\n",
    "Required packages that are not dependencies: opencv-python, GhostScript local machine installation.\n",
    "`pip install camelot-py` with `pip install opencv-python` should handle the cv2 dependency that tends to raise an error, and `pip install camelot-py[cv]` should work as well.\n",
    "\n",
    "For GhostScript, visit their website since a local machine installation is necessary. A PATH environment variable to path `C:\\Program Files\\gs\\gs\"x.xx.x\"\\bin` is necessary as well, but after camelot should work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "african-hundred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deciles\\nםינורישע</td>\n",
       "      <td>לכה ךס\\nTotal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10\\n9\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.0\\n83.7\\n81.0\\n81.1\\n79.9\\n77.4\\n71.7\\n63.6...</td>\n",
       "      <td>70.2\\n70.0\\n71.1\\n70.8\\n71.2\\n69.6\\n70.4\\n70.6...</td>\n",
       "      <td>1997\\n1998\\n1999\\n2000\\n2001\\n2002\\n2003\\n2004...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                                  Deciles\\nםינורישע   \n",
       "1                      10\\n9\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n1   \n",
       "2  84.0\\n83.7\\n81.0\\n81.1\\n79.9\\n77.4\\n71.7\\n63.6...   \n",
       "\n",
       "                                                   1  \\\n",
       "0                                      לכה ךס\\nTotal   \n",
       "1                                                      \n",
       "2  70.2\\n70.0\\n71.1\\n70.8\\n71.2\\n69.6\\n70.4\\n70.6...   \n",
       "\n",
       "                                                   2  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  1997\\n1998\\n1999\\n2000\\n2001\\n2002\\n2003\\n2004...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import camelot\n",
    "# extract all the tables in the PDF file\n",
    "df = camelot.read_pdf(path)\n",
    "df[0].df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-texas",
   "metadata": {},
   "source": [
    "It's not in a super readable format, but it's definitely a start over Tabula! Additionally, settings can be tweaked to fine-tune camelot to better read the table region. Inexplicably, Camelot could not read the sample table provided from GeeksForGeeks using their provided code, even with additional tweaking... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-seeker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
